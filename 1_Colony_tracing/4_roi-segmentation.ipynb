{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d948fb-a985-4ecb-a505-d67f8c493091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jz-rolling/Desktop/OMEGA_GUI/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jz-rolling/Desktop/OMEGA_GUI/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f08527-ec75-4f78-b5f0-ff0191241b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import momia2 as mo\n",
    "from skimage import measure, feature, filters, transform, morphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import read_roi as rr\n",
    "import matplotlib.pyplot as plt\n",
    "import glob,os\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "160aa00e-e3d1-44ec-9f33-87c95cacea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mo.classify.classifier.load_model('/Users/jz-rolling/Desktop/Size_calculation/training_set/model_20220101.pk')\n",
    "gabor_kernels = prepare_gabor_kernels()\n",
    "pad=20\n",
    "src = '/Users/jz-rolling/Desktop/Size_calculation/20220118/Alignment_20220120/'\n",
    "dst = '/Users/jz-rolling/Desktop/Size_calculation/20220118/Cropped_20220120/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "91b977cd-ae66-4c51-a60a-7b72083796cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for f in sorted(glob.glob(src+'Plate-7/')):\n",
    "    plate = f.split('/')[-2]\n",
    "    rois = rr.read_roi_zip(f+'{}_roi.zip'.format(plate))\n",
    "    images = []\n",
    "    days = []\n",
    "    for img in sorted(glob.glob(f+'*.tif')):\n",
    "        images.append(plt.imread(img))\n",
    "        days.append(int(img.split('/')[-1].split('_')[0]))\n",
    "    args = np.argsort(days)\n",
    "    sorted_days = np.array(days)[args]\n",
    "    sorted_images = np.array(images)[args]\n",
    "    img_h,img_w = images[0].shape\n",
    "    for i,k in enumerate(rois.keys()):\n",
    "        roi_data = {}\n",
    "        v=rois.get(k)\n",
    "        x1,y1 = v['top'],v['left']\n",
    "        x2,y2 = x1+v['height'],y1+v['width']\n",
    "        \n",
    "        pad_top = min(pad,x1)\n",
    "        pad_left = min(pad,y1)\n",
    "        pad_bottom = min(pad,img_h-x2-1)\n",
    "        pad_right = min(pad,img_w-y2-1)\n",
    "        window = sorted_images[:,x1-pad_top:x2+pad_bottom,y1-pad_left:y2+pad_right]\n",
    "        corrected,_w = correct_tl(window)\n",
    "        corrected_cropped = np.array([x[pad_top:-pad_bottom,pad_left:-pad_right] for x in corrected])\n",
    "        masks = []\n",
    "        mask_probs = []\n",
    "        edges = []\n",
    "        for s in corrected_cropped:\n",
    "            prob,fg,edge= image2labels(s,model,\n",
    "                                       gabor_kernels=gabor_kernels,\n",
    "                                       edge_threshold=0.2)\n",
    "            masks.append(fg)\n",
    "            mask_probs.append(prob)\n",
    "            edges.append(edge)\n",
    "        masks=np.array(masks)\n",
    "        mask_probs=np.array(mask_probs)\n",
    "        edges = np.array(edges)\n",
    "        roi_data['Days'] = sorted_days\n",
    "        roi_data['Images'] = corrected_cropped\n",
    "        roi_data['Masks'] = masks\n",
    "        roi_data['Mask_probs'] = mask_probs\n",
    "        roi_data['Edges'] = edges\n",
    "        fname = dst+'{}_{}.pk'.format(plate,k)\n",
    "        pk.dump(roi_data,open(fname,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7e4cf93e-50b3-404c-9e45-cd1e32ca4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import gabor_kernel\n",
    "def prepare_gabor_kernels(n_theta=4,sigmas=[2.8],frequencies=[0.23]):\n",
    "    kernels = []\n",
    "    for theta in range(n_theta):\n",
    "        theta = (theta / n_theta) * np.pi\n",
    "        for sigma in sigmas:\n",
    "            for frequency in frequencies:\n",
    "                kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                              sigma_x=sigma, sigma_y=sigma))\n",
    "                kernels.append(kernel)\n",
    "    return kernels\n",
    "\n",
    "\n",
    "def min_max(data):\n",
    "    return (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "def power(image, kernel):\n",
    "    # Normalize images for better comparison.\n",
    "    image = (image - image.mean()) / image.std()\n",
    "    power_image = np.sqrt(ndi.convolve(image, np.real(kernel), mode='wrap')**2 +\n",
    "                          ndi.convolve(image, np.imag(kernel), mode='wrap')**2)\n",
    "    convolved = filters.gaussian(power_image/np.median(power_image),sigma=0.8)\n",
    "    return convolved\n",
    "\n",
    "def image2labels(target,model,gabor_kernels,edge_threshold = 0.05):\n",
    "    target = target.astype(int)\n",
    "    target = (target/240)*255\n",
    "    target[target>255]=255\n",
    "    target = mo.utils.dual_bandpass(target,\n",
    "                                    pixel_microns=1,\n",
    "                                    min_structure_scale=1,\n",
    "                                    max_structure_scale=400).astype(np.uint8)\n",
    "    x,y = np.where(target>-1)\n",
    "    gaussians,img_features = mo.metrics.image_feature.multiscale_image_feature(target,sigmas=(1,2.5,5),\n",
    "                                                                               shapeindex=True,\n",
    "                                                                               rog=True)\n",
    "    pixel_stats = mo.metrics.image_feature.local_stat(img_features,x,y)\n",
    "    for i,g in enumerate(gabor_kernels):\n",
    "        filtered = power(target, g)\n",
    "        pixel_stats['Gabor_{}'.format(i)] = filtered[x,y]\n",
    "    mask = np.zeros(list(target.shape))\n",
    "    mask_prob = np.zeros(list(target.shape)+[3])\n",
    "    predictions = model.predict(pixel_stats,probability=False)\n",
    "    probs = model.predict(pixel_stats,probability=True)\n",
    "    mask_prob[x,y,:] = probs\n",
    "    mask[x,y,] = predictions\n",
    "    fg = morphology.binary_opening(mask==1)\n",
    "    fg = morphology.remove_small_holes(fg,200)\n",
    "    edge = (mask_prob[:,:,2])>edge_threshold\n",
    "    edge = morphology.binary_opening(edge)\n",
    "    return mask_prob,fg,edge\n",
    "\n",
    "def min_max(data):\n",
    "    return (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "def xydrift_correction(target_img, shift, max_drift=25):\n",
    "    if max(np.abs(shift)) <= max_drift:\n",
    "        return shift_image(target_img, np.array(shift))\n",
    "    else:\n",
    "        return target_img\n",
    "    \n",
    "def get_xydrift(ref_img, target_img):\n",
    "    from skimage import registration\n",
    "    shift, error, _diff = registration.phase_cross_correlation(ref_img, target_img, upsample_factor=10)\n",
    "    return shift\n",
    "\n",
    "def shift_image(img, shift):\n",
    "    from scipy import ndimage as ndi\n",
    "    \"\"\"\n",
    "    correct xy drift between phase contrast image and fluorescent image(s)\n",
    "    :param img: input image\n",
    "    :param shift: subpixel xy drift\n",
    "    :return: drift corrected image\n",
    "    \"\"\"\n",
    "    offset_image = ndi.fourier_shift(np.fft.fftn(img), shift)\n",
    "    offset_image = np.fft.ifftn(offset_image)\n",
    "    offset_image = np.round(offset_image.real)\n",
    "    return offset_image\n",
    "\n",
    "\n",
    "def correct_tl(pos_data,max_drift=20):\n",
    "    is_weird = [0]\n",
    "    last_drift = np.array([0,0])\n",
    "    output_data = []\n",
    "    for t in range(len(pos_data)):\n",
    "        if t == 0:\n",
    "            output_data.append(pos_data[t])\n",
    "        else:\n",
    "            shift = get_xydrift(pos_data[t-1],pos_data[t])\n",
    "            if np.abs(shift).max()>max_drift:\n",
    "                is_weird.append(1)\n",
    "            else:\n",
    "                is_weird.append(0)\n",
    "            last_drift = last_drift + shift\n",
    "            output_data.append(xydrift_correction(pos_data[t],last_drift,max_drift=max_drift))\n",
    "    output_data = np.array(output_data)\n",
    "    return output_data, is_weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ec3d6-fbf8-4795-ab0c-eed7b3d95f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
